[
    {
      "title": "Stock Market Web and iOS Application",
      "overview": "Developed a stock market application utilizing the MERN stack (MongoDB, Express.js, React, Node.js) for the web version and a native iOS app using Swift and SwiftUI.",
      "category": "android",
      "technologies": [
        "MERN Stack: For building the web application, allowing real-time data retrieval and interactive visualizations.",
        "AWS: Deployed application on Amazon Web Services for scalability and reliability.",
        "Finnhub API: Integrated for real-time stock market data retrieval.",
        "Highcharts: Used for creating interactive stock visualizations."
      ],
      "libraries": [
        {
          "name": "Alamofire",
          "url": "https://github.com/Alamofire/Alamofire"
        },
        {
          "name": "SwiftyJSON",
          "url": "https://github.com/SwiftyJSON/SwiftyJSON"
        },
        {
          "name": "Kingfisher",
          "url": "https://github.com/onevcat/Kingfisher"
        }
      ],
      "visuals": [
        {
          "type": "video",
          "src": "media/stock_market/HW3_responsive_demo.mov",
          "alt": "Web Responsive Version"
        },
        {
          "type": "video",
          "src": "media/stock_market/HW3_web_demo.mov",
          "alt": "Web Version"
        },
        {
          "type": "video",
          "src": "media/stock_market/Assignment4varunjay.mp4",
          "alt": "Mobile Application Using SwiftUI"
        }
      ]
    },
    {
      "title": "Waste Classification using Transfer Learning",
      "overview": "This project focuses on classifying waste into six categories: cardboard, glass, metal, organic, paper, and plastic using Transfer Learning with Convolutional Neural Networks (CNNs).",
      "methodology": "The initial approach involved image classification using Support Vector Machines (SVM). However, due to poor accuracy, we transitioned to deep learning. We employed a CNN architecture to improve classification accuracy by processing images through multiple layers, enabling the model to learn complex features.",
      "category": "android",
      "cnn_architecture": [
        "Convolutional Layers: Detect basic features such as edges and colors.",
        "Pooling Layers: Reduce dimensionality and summarize features.",
        "Flattening Layer: Convert the 2D feature maps into a 1D vector.",
        "Fully Connected Layers: Classify the output based on learned features."
      ],
      "transfer_learning": "We utilized ResNet50v2, a pre-trained model known for its robustness and depth. This model was fine-tuned for our waste classification task by unfreezing some layers and adding additional dense layers to adapt to our specific output classes.",
      "training_process": "We trained the model on an augmented dataset (80% training, 20% validation) using various data augmentation techniques to enhance generalization. The optimal learning rate was determined to be 0.00001, yielding the best accuracy.",
      "applications": "This image classification system can significantly improve waste management practices, helping to segregate recyclable and non-recyclable materials effectively, thus reducing manual labor and enhancing safety for waste workers.",
      "visuals": [
        {
          "type": "image",
          "src": "media/waste_classification/Screenshot 2024-10-04 at 3.59.17 PM.png",
          "alt": "ResNet50v2 structure"
        },
        {
          "type": "image",
          "src": "media/waste_classification/Screenshot 2024-10-04 at 3.59.37 PM.png",
          "alt": "Data Augmentation Techniques"
        },
        {
          "type": "image",
          "src": "media/waste_classification/Screenshot 2024-10-04 at 4.00.04 PM.png",
          "alt": "Training Accuracy Graph"
        },
        {
          "type": "image",
          "src": "media/waste_classification/Screenshot 2024-10-04 at 4.00.20 PM.png",
          "alt": "Sample Waste Classification Result"
        },
        {
          "type": "image",
          "src": "media/waste_classification/Screenshot 2024-10-04 at 4.00.44 PM.png",
          "alt": "Confusion Matrix"
        }
      ]
    },
    {
      "title": "OCR for Medical Reports: Enhanced Data Extraction and Summarization",
      "overview": "This project aims to enhance data extraction and summarization of medical reports using OCR technology and machine learning.",
      "category": "android",
      "key_highlights": [
        "Combined information extraction and summarization for better comprehension.",
        "Developed a Medical Dictionary in collaboration with local doctors.",
        "Utilized AWS Textract for accurate data extraction from medical records.",
        "Implemented a summarization model using GPT-2 to generate user-friendly reports."
      ],
      "results": "Achieved high accuracy in recognizing structured data, leading to improved analysis and insights for healthcare professionals.",
      "visuals": [
        {
          "type": "image",
          "src": "media/medical_report/Screenshot 2024-10-04 at 3.08.29 PM.png",
          "alt": "System Flow"
        },
        {
          "type": "image",
          "src": "media/medical_report/Screenshot 2024-10-04 at 3.09.15 PM.png",
          "alt": "Example of a Medical Report"
        },
        {
          "type": "image",
          "src": "media/medical_report/Screenshot 2024-10-04 at 3.09.40 PM.png",
          "alt": "Report generated after OCR"
        },
        {
          "type": "image",
          "src": "media/medical_report/Screenshot 2024-10-04 at 3.10.07 PM.png",
          "alt": "Abnormal Parameters obtained after OCR"
        }
      ]
    }
  ]
